{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Clone github repository##\n",
    "!git clone https://github.com/liraserge26/TFG_Mask_RCNN.git\n",
    "    \n",
    "!pip uninstall keras-nightly\n",
    "!pip uninstall -y tensorflow\n",
    "!pip uninstall -y imgaug\n",
    "\n",
    "!pip install imgaug==0.2.6\n",
    "!pip install -U scikit-image==0.16.2\n",
    "!pip install h5py==2.10.0\n",
    "!pip install tensorflow==1.15\n",
    "!pip install tensorflow-gpu==1.15.0\n",
    "!pip install keras==2.1.6\n",
    "\n",
    "%cd TFG_Mask_RCNN\n",
    "\n",
    "!pip3 install -r requirements.txt\n",
    "!python3 setup.py install\n",
    "\n",
    "!git clone https://github.com/cocodataset/cocoapi.git\n",
    "%cd cocoapi/PythonAPI\n",
    "!make\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATIONS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import imgaug\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"/content/drive/MyDrive/TFG/Mask_RCNN/Data/PCB_Holes/Experiment_1\")\n",
    "\n",
    "sys.path.append(ROOT_DIR)  \n",
    "\n",
    "from mrcnn.config import Config\n",
    "\n",
    "from mrcnn import utils\n",
    "\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "from mrcnn import visualize\n",
    "\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "\n",
    "COCO_MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "if not os.path.exists(COCO_MODEL_PATH) or not os.path.exists(COCO_MODEL_PATH_2):\n",
    "  %cd Data/PCB_Holes/Experiment_1/logs\n",
    "  utils.download_trained_weights(os.path.join(os.path.abspath(\"../\"),\"mask_rcnn_coco.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "Holes_Verification_DATA_DIR = '/content/drive/MyDrive/TFG/Mask_RCNN/Data/'\n",
    "\n",
    "DATASET_DIR = os.path.join(Holes_Verification_DATA_DIR,'PCB_Holes')   \n",
    "\n",
    "DATASET_TRAIN_DIR = os.path.join(DATASET_DIR, 'LabelImg_JSON/train')\n",
    "DATASET_VAL_DIR = os.path.join(DATASET_DIR, 'LabelImg_JSON/val')\n",
    "DATASET_TEST_DIR = os.path.join(DATASET_DIR, 'LabelImg_JSON/test')\n",
    "\n",
    "config = ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCB_Data(Config):\n",
    "    \"\"\"Configuration for training on the Raps  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    NAME = \"PCB_Data\"\n",
    "\n",
    "    IMAGES_PER_GPU = 1\n",
    "  \n",
    "\n",
    "    NUM_CLASSES = 1 + 2 # Background + Holes_Ok + Hole_Not_Ok \n",
    "\n",
    "\n",
    "    STEPS_PER_EPOCH = 86 \n",
    "\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.1\n",
    "    DETECTION_NMS_THRESHOLD = 0.1\n",
    "    DETECTION_MAX_INSTANCES = 500\n",
    "\n",
    "\n",
    "    USE_MINI_MASK = True\n",
    "\n",
    "    IMAGE_SHAPE = [1024,1024,3]\n",
    "    BATCH_SIZE =4\n",
    "\n",
    "    LEARNING_RATE=0.005\n",
    "\n",
    "\t\n",
    "config = PCB_Data()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageDraw\n",
    "\n",
    "class PCB_dataDataset(utils.Dataset):\n",
    "    def load_dataset(self, dataset_dir):\n",
    "        self.add_class('dataset', 1, 'hole_ok')\n",
    "\n",
    "        self.add_class('dataset', 2, 'hole_not_ok')\n",
    "        for i, filename in enumerate(os.listdir(dataset_dir)):\n",
    "            annotation_file = os.path.join(dataset_dir, filename.replace('.jpg', '.json'))\n",
    "            if '.jpg' in filename and os.path.isfile(annotation_file):\n",
    "                    self.add_image('dataset', \n",
    "                               image_id=i, \n",
    "                               path=os.path.join(dataset_dir, filename),\n",
    "                               annotation=annotation_file)\n",
    "    \n",
    "    \n",
    "    def extract_masks(self, filename, image_id):\n",
    "        print(image_id)\n",
    "        image = self.load_image(image_id)\n",
    "        json_file = os.path.join(filename)\n",
    "        with open(json_file) as f:\n",
    "            img_anns = json.load(f)\n",
    "\n",
    "        n_masks = 0\n",
    "        for shape in img_anns[0]['annotations']:\n",
    "          if shape['label']=='hole_ok' or 'hole_not_ok':\n",
    "            n_masks+=1\n",
    "       \n",
    "        masks = np.zeros([image.shape[0], image.shape[1], n_masks], dtype='uint8')\n",
    "        classes = []\n",
    "        i=0\n",
    "        for shape in img_anns[0]['annotations']:\n",
    "          area = self.shape_area(shape['coordinates'])\n",
    "          mask = np.zeros([image.shape[0], image.shape[1]], dtype='uint8')\n",
    "          cv2.fillPoly(mask, area, 255)\n",
    "          masks[:, :, i] = mask                                          \n",
    "          classes.append(self.class_names.index(shape['label']))\n",
    "          i+=1\n",
    "        return masks, classes\n",
    " \n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['annotation']\n",
    "        masks, classes = self.extract_masks(path, image_id)\n",
    "        return masks, np.asarray(classes, dtype='int32')\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def shape_area(self, bbox):\n",
    "        x=(bbox['x'])\n",
    "        y=(bbox['y'])\n",
    "        width=(bbox['width'])\n",
    "        height=(bbox['height'])\n",
    "        x0=(x-(width/2))\n",
    "        y0=(y-(height/2))\n",
    "        xf=(x+(width/2))\n",
    "        yf=(y+(height/2))\n",
    "        p1=([int(x0), int(yf)])\n",
    "        p2=([int(xf), int(yf)])\n",
    "        p3=([int(xf), int(y0)])\n",
    "        p4=([int(x0), int(y0)])\n",
    "        area = np.array([[p1, p2, p3, p4]], dtype=np.int32)\n",
    "        return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = PCB_dataDataset()\n",
    "dataset_train.load_dataset(DATASET_TRAIN_DIR)\n",
    "dataset_train.prepare()\n",
    "print('Training:')\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_train.num_classes))\n",
    "for i, info in enumerate(dataset_train.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n",
    " \n",
    "dataset_val = PCB_dataDataset()\n",
    "dataset_val.load_dataset(DATASET_VAL_DIR)\n",
    "dataset_val.prepare()\n",
    "print('Validation:')\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n",
    "dataset_test = PCB_dataDataset()\n",
    "dataset_test.load_dataset(DATASET_TEST_DIR)\n",
    "dataset_test.prepare()\n",
    "print('Test:')\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_test.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_test.num_classes))\n",
    "for i, info in enumerate(dataset_test.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Choose 5 random images from training dataset and visualize masks##\n",
    "\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 5)\n",
    "for image_id in image_ids:\n",
    "  image = dataset_train.load_image(image_id)\n",
    "  mask, class_ids = dataset_train.load_mask(image_id)\n",
    "  visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##init_with==\"coco\" if we train the model with random weights\n",
    "##init_with==\"lats\" if we train the model with the last calculated weights\n",
    "\n",
    "init_with = \"last\"  \n",
    "\n",
    "if init_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##with layers=\"heads\" we train the last layers for training specific features.\n",
    "\n",
    "PCB_augmentation = imgaug.augmenters.Sometimes(0.5,\n",
    "    [imgaug.augmenters.geometric.Affine(rotate=(-360,360))])\n",
    "    \n",
    "    \n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=130,\n",
    "            layers='heads',augmentation = PCB_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##with layers=\"all\" we train all the layers.\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=120, \n",
    "            layers=\"all\", augmentation = PCB_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create the model in inference mode\n",
    "class InferenceConfig(PCB_Data):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "model_path = model.find_last()\n",
    "\n",
    "\n",
    "print(\"Loading weights from \", model_path)\n",
    "\n",
    "model.load_weights(model_path, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Choose a random image from test dataset and visualize the mask\n",
    "image_id = np.random.choice(dataset_test.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_test, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "                            dataset_train.class_names, figsize=(12, 12))\n",
    "\n",
    "print(gt_class_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save predicted mask from the random image and visualize it\n",
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_test.class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save all predicted masks from test dataset and visualize the results using confusion matrix algorithm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from mrcnn import utils_cm\n",
    "from mrcnn import utils\n",
    "\n",
    "\n",
    "gt_tot = np.array([])\n",
    "pred_tot = np.array([])\n",
    "\n",
    "mAP_ = []\n",
    "\n",
    "\n",
    "for image_id in dataset_test.image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_test, config, image_id, use_mini_mask=False)\n",
    "    info = dataset_test.image_info[image_id]\n",
    "\n",
    "\n",
    "    results = model.detect([image], verbose=1)\n",
    "    r = results[0]\n",
    "\n",
    "    gt, pred = utils_cm.gt_pred_lists(gt_class_id, gt_bbox, r['class_ids'], r['rois'])\n",
    "    gt_tot = np.append(gt_tot, gt)\n",
    "    pred_tot = np.append(pred_tot, pred)\n",
    "    \n",
    "\n",
    "    AP_, precision_, recall_, overlap_ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "\n",
    "    print(\"the actual len of the gt vect is : \", len(gt_tot))\n",
    "    print(\"the actual len of the pred vect is : \", len(pred_tot))\n",
    "    \n",
    "    mAP_.append(AP_)\n",
    "    print(\"Average precision of this image : \",AP_)\n",
    "    print(\"The actual mean average precision for the whole images (matterport methode) \", sum(mAP_)/len(mAP_))\n",
    "  \n",
    "gt_tot=gt_tot.astype(int)\n",
    "pred_tot=pred_tot.astype(int)\n",
    "\n",
    "save_dir = os.path.join(MODEL_DIR, \"Confusion_Matrix\")\n",
    "gt_pred_tot_json = {\"gt_tot\" : gt_tot, \"pred_tot\" : pred_tot}\n",
    "df = pd.DataFrame(gt_pred_tot_json)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "df.to_json(os.path.join(save_dir,\"gt_pred_test.json\"))\n",
    "\n",
    "gt_class_id = np.array([1,2,1,2]) #[hole_ok, hole_not_ok, hole_ok, hole_not_ok]\n",
    "\n",
    "print(\"ground truth list : \",gt_tot)\n",
    "print(\"predicted list : \",pred_tot)\n",
    "print(gt_tot)\n",
    "print(pred_tot)\n",
    "\n",
    "tp,fp,fn=utils_cm.plot_confusion_matrix_from_data(gt_tot,pred_tot,dataset_test.class_names,fz=18, figsize=(20,20), lw=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
